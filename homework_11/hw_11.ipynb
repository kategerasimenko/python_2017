{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11  \n",
    "Implement Hidden Markov Model with supervised training and Viterbi algorithm for finding the most probable sequence of hidden states. Use [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) for estimation of probabilities. Apply the developed model to the problems:\n",
    "* part of speech tagging\n",
    "* spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image\n",
    "from collections import defaultdict\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM model for 3-grams:\n",
    "\n",
    "$P(x_1, .., x_T, y_1, .., y_T, y_{T+1}) = \\prod_{t=1}^{T+1} q(y_t | y_{t-2}, y_{t-1}) \\prod_{t=1}^T e(x_t | y_t)$\n",
    "\n",
    "$x_1, .., x_T$ - sequence of observed states of length T  \n",
    "$y_1, .., y_T$ - sequence of hidden states of length T  \n",
    "$q(i | u, v) = \\frac {count(u, v, i)} {count(u, v)} $ - transition probability   \n",
    "$e(x_k | i) = \\frac {count(i, x_k)} {count(i)}$ - emission probability  \n",
    "$A_{i,j} = A_{(u,v), j} = q(i | u, v)$ - transition matrix  \n",
    "$B_{j,k} = e(x_k | j)$ - emission matrix  \n",
    "\n",
    "We assume, that $y_{T+1} = TERM$, and $y_0 = y_{-1} = START$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    START = '*'\n",
    "    TERM = '$'\n",
    "    REST = '$REST$' # to deal with observed states who have never appeared in train dataset.\n",
    "        \n",
    "    def cond_idx(self, u, v):\n",
    "        return u + v*self.h_dim\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X - list of lists, observed states\n",
    "        y - list of lists, hidden states\n",
    "        estimate elements of A, B matrices from train sequence. \n",
    "        \"\"\"\n",
    "        \n",
    "        X_flat = [xx for yy in X for xx in yy]\n",
    "        y_flat = [xx for yy in y for xx in yy]\n",
    "        \n",
    "        self.hidden_idx2state = list(set(y_flat)) + [self.START, self.TERM]\n",
    "        self.hidden_states = {x:i for i,x in enumerate(self.hidden_idx2state)}\n",
    "        self.h_dim = len(self.hidden_idx2state)\n",
    "\n",
    "        self.observed_idx2state = list(set(X_flat)) + [self.REST]\n",
    "        self.observed_states = {x:i for i,x in enumerate(self.observed_idx2state)}\n",
    "        self.o_dim = len(self.observed_idx2state)\n",
    "        \n",
    "        #######################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # self.hidden_idx2state = # lisf of unique hidden states in train sequence + [START, TERM]\n",
    "        # self.hidden_states = # from state name to state index in hidden_idx2state\n",
    "        # self.h_dim = number of hidden states\n",
    "        \n",
    "        # self.observed_idx2state = # lisf of unique observed states in train sequence + [REST]\n",
    "        # self.observed_states = # from state name to state index in hidden_idx2state\n",
    "        # self.o_dim = number of observed states\n",
    "        \n",
    "        #######################       \n",
    "        \n",
    "        ########################\n",
    "        # transition matrix\n",
    "        # YOUR CODE HERE\n",
    "        # self.A = dense matrix of shape (h_dim **2, h_dim)\n",
    "        # remember about padding for sequence of hidden states, eg {a, b} -> {START, START, a, b, TERM}\n",
    "        ########################        \n",
    "        \n",
    "        #######################\n",
    "        # estimate emission matrix\n",
    "        # YOUR CODE HERE\n",
    "        # self.B = sparse csr matrix of shape (h_dim, o_dim)\n",
    "        #######################\n",
    "        \n",
    "        self.A = sparse.csr_matrix((self.h_dim**2, self.h_dim))\n",
    "        self.B = np.zeros(((self.h_dim, self.o_dim)))\n",
    "        \n",
    "        for h_el, o_el in zip(y,X):\n",
    "            row = [self.START, self.START] + h_el\n",
    "            for i in range(2,len(row)):\n",
    "                prev = self.cond_idx(self.hidden_states[row[i-2]],self.hidden_states[row[i-1]])\n",
    "                curr_h = self.hidden_states[row[i]]\n",
    "                curr_o = self.observed_states[o_el[i-2]]\n",
    "                self.A[prev,curr_h] += 1\n",
    "                self.B[curr_h,curr_o] += 1\n",
    "            prev = self.cond_idx(self.hidden_states[row[i-1]],self.hidden_states[row[i]])\n",
    "            curr_h = self.hidden_states[self.TERM]\n",
    "            self.A[prev,curr_h] += 1\n",
    "                \n",
    "        self.A_rowsum = np.ravel(self.A.sum(axis=1))\n",
    "        self.B_rowsum = np.ravel(self.B.sum(axis=1))\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tr_prob(self, i, j): # i prev, j curr\n",
    "        \"\"\"\n",
    "        A_ij = q(j | i) = q(j| u, v) with Laplace smoothing\n",
    "        \"\"\"\n",
    "        result = (self.A[i,j] + 1) / (self.A_rowsum[i] + self.h_dim)\n",
    "        ########################\n",
    "        # YOUR CODE HERE\n",
    "        # result = smoothed probability\n",
    "        ########################\n",
    "        return result\n",
    "    \n",
    "    def em_prob(self, i, j): # i hidden, j observed\n",
    "        \"\"\"\n",
    "        B_jk = e(x_k| j) with Laplace smoothing\n",
    "        \"\"\"\n",
    "        result = (self.B[i,j] + 1) / (self.B_rowsum[i] + self.o_dim)\n",
    "        ########################\n",
    "        # YOUR CODE HERE\n",
    "        # result = smoothed probability\n",
    "        ########################\n",
    "        return result\n",
    "        \n",
    "    def o_state(self, x):\n",
    "        \"\"\"\n",
    "        return index of obseved state\n",
    "        \"\"\"\n",
    "        return self.observed_states.get(x, self.observed_states[self.REST])\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the most probable sequence of hidden states for every sequence of observed states\n",
    "        X - list of lists\n",
    "        \"\"\"\n",
    "        y_pred = [self._viterbi(seq) for seq in tqdm(X)]\n",
    "        return y_pred \n",
    "            \n",
    "    def _viterbi(self, X):\n",
    "        \"\"\"\n",
    "        X - list of observables\n",
    "        product of probabilities usually is not numerically stable\n",
    "        remember, that log(ab) = log(a) + log(b) and argmax[log(f(x))] = argmax[f(x)]\n",
    "        \n",
    "        \"\"\"   \n",
    "        T = len(X)\n",
    "        \n",
    "        # pi[t, u, v] - max probability for any state sequence ending with x_t = v and x_{t-1} = u.\n",
    "        pi = np.zeros((T + 1, self.h_dim, self.h_dim))\n",
    "        # backpointers, bp[t, u, v] = argmax probability for any state sequence ending with x_t = v and x_{t-1} = u.\n",
    "        bp = np.zeros((T + 1, self.h_dim, self.h_dim), dtype=np.int)\n",
    "        \n",
    "        ###################\n",
    "        # fill tables pi and bp\n",
    "        # pi[t, u, v] = max_{w} [ pi[t-1, w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # bp[t, u, v] = argmax_{w} [ pi[t-1, w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # YOUR CODE HERE \n",
    "        x0 = self.o_state(X[0])\n",
    "        start_idx = self.hidden_states[self.START]\n",
    "        for v in range(self.h_dim):\n",
    "            log_b_smoothed = self.em_prob(v,x0)\n",
    "            log_a_smoothed = self.tr_prob(self.cond_idx(start_idx,start_idx),v)\n",
    "            pi[0,start_idx,v] = log_a_smoothed * log_b_smoothed\n",
    "        \n",
    "        for k in range(1, T):\n",
    "            xk = self.o_state(X[k])\n",
    "\n",
    "            for v in range(self.h_dim):\n",
    "                log_b_smoothed = self.em_prob(v,xk)\n",
    "                for u in range(self.h_dim): \n",
    "                    r = np.zeros(self.h_dim)\n",
    "                    for w in range(self.h_dim):\n",
    "                        log_a_smoothed = self.tr_prob(self.cond_idx(w,u),v)\n",
    "                        r[w] = pi[k-1, w, u] * log_a_smoothed * log_b_smoothed\n",
    "                    bp[k, u, v] = np.argmax(r)\n",
    "                    pi[k, u, v] = np.max(r)\n",
    "        ###################\n",
    "                    \n",
    "        term_idx = self.hidden_states[self.TERM]\n",
    "        \n",
    "        ###################\n",
    "        # r(u,v) = pi[T, u, v] * q(TERM | u, v)\n",
    "        # find argmax_{u, v} r(u, v)\n",
    "        # YOUR CODE HERE\n",
    "        r = np.zeros((self.h_dim,self.h_dim))\n",
    "        for u in range(self.h_dim):\n",
    "            for v in range(self.h_dim):\n",
    "                r[u,v] = pi[k,u,v] * self.tr_prob(self.cond_idx(u,v),term_idx)\n",
    "        u, v = np.unravel_index(np.argmax(r), r.shape)\n",
    "        ###################\n",
    "        \n",
    "        h_states = [v, u]\n",
    "        ###################\n",
    "        # rollback backpointers\n",
    "        # y_{t-2} = bp[t, y_{t-1}, y_t]\n",
    "        # h_states is a reversed sequence of hidden states\n",
    "        # YOUR CODE HERE\n",
    "        for k in range(T-1,1,-1):\n",
    "            h_states.append(bp[k, h_states[-1], h_states[-2]]) \n",
    "        ###################\n",
    "            \n",
    "        return [self.hidden_idx2state[i] for i in reversed(h_states[:T])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Part of speech tagging\n",
    "\n",
    "Build Part-of-Speech tagging model using HMM. Estimate accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to D:\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import treebank\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "tags:  NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\n"
     ]
    }
   ],
   "source": [
    "data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:3010]\n",
    "\n",
    "X_train = [[x[0] for x in y] for y in data]\n",
    "y_train = [[x[1] for x in y] for y in data]\n",
    "\n",
    "X_test = [[x[0] for x in y] for y in test_data]\n",
    "y_test = [[x[1] for x in y] for y in test_data]\n",
    "\n",
    "print('sentence: ', \" \".join(X_train[0]))\n",
    "print('tags: ', \" \".join(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):       \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Андрей\\Anaconda3\\envs\\python36\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      " 10%|████▎                                      | 1/10 [01:33<14:05, 93.91s/it]\n",
      " 20%|████████▌                                  | 2/10 [02:41<10:47, 80.94s/it]\n",
      " 30%|████████████▉                              | 3/10 [04:03<09:27, 81.11s/it]\n",
      " 40%|█████████████████▏                         | 4/10 [04:38<06:57, 69.59s/it]\n",
      " 50%|█████████████████████▌                     | 5/10 [06:10<06:10, 74.07s/it]\n",
      " 60%|█████████████████████████▊                 | 6/10 [07:28<04:59, 74.78s/it]\n",
      " 70%|██████████████████████████████             | 7/10 [09:05<03:53, 77.91s/it]\n",
      " 80%|██████████████████████████████████▍        | 8/10 [10:09<02:32, 76.20s/it]\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [11:05<01:13, 73.92s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [13:16<00:00, 79.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757847533632\n",
      "Wall time: 13min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hh = HMM().fit(X_train, y_train)\n",
    "y_pred = hh.predict(X_test)\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accuracy must be > 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.2 Vectorized viterbi\n",
    "Our currrent implementation of Viterbi is too slow. Let's make it vectorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HmmVectorized(HMM):\n",
    "    \n",
    "    def _viterbi(self, X):\n",
    "        \"\"\"\n",
    "        Vectorized version of Viterbi. Let's speed up!\n",
    "        X - list of observables\n",
    "        \"\"\"   \n",
    "        T = len(X)\n",
    "        \n",
    "        # One may notice, at every step t we only need pi[t-1, u, v] = pi_prev[u,v] to compute pi[t, u, v] = pi_curr[u,v]\n",
    "        pi_prev = np.zeros((self.h_dim, self.h_dim))\n",
    "        \n",
    "        # backpointers\n",
    "        bp = np.zeros((T + 1, self.h_dim, self.h_dim), dtype=np.int)\n",
    "        \n",
    "        #a_rowsum = self.A_rowsum.reshape(self.h_dim, self.h_dim)\n",
    "        \n",
    "        ###################\n",
    "        # fill pi and bp\n",
    "        # pi_curr[u, v] = max_{w} [ pi_prev[w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # bp[t, u, v] = argmax_{w} [ pi_prev[w, u] * q(v| w, u) * e(x_k| v) ]\n",
    "        # don't use tr_prob() and em_prob(), apply laplace smoothing directly here\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        x0 = self.o_state(X[0])\n",
    "        start_idx = self.hidden_states[self.START]\n",
    "        for v in range(self.h_dim):\n",
    "            log_b_smoothed = self.em_prob(v,x0)\n",
    "            log_a_smoothed = self.tr_prob(self.cond_idx(start_idx,start_idx),v)\n",
    "            pi_prev[start_idx,v] = log_a_smoothed * log_b_smoothed\n",
    "\n",
    "        for k in range(1, T):            \n",
    "            xk = self.o_state(X[k])\n",
    "            pi_curr = np.zeros_like(pi_prev)\n",
    "            \n",
    "            for v in range(self.h_dim):\n",
    "                log_b_smoothed = (self.B[:, xk] + 1) / (self.B_rowsum + self.o_dim)\n",
    "                #a = self.A[:, v].reshape(self.h_dim, self.h_dim)\n",
    "                log_a_smoothed = (self.A[:, v] + 1) / (self.A_rowsum + self.h_dim)\n",
    "                r = log_b_smoothed * log_a_smoothed * pi_prev # переделать\n",
    "                bp[k, :, v] = np.argmax(r, axis=1)\n",
    "                pi_curr[:, v] = np.max(r, axis=1)\n",
    "                    \n",
    "            pi_prev = pi_curr\n",
    "        ###################\n",
    "        \n",
    "        term_idx = self.hidden_states[self.TERM]\n",
    "        \n",
    "        ###################\n",
    "        # r(u,v) = pi[T, u, v] * q(TERM | u, v)\n",
    "        # find argmax_{u, v} r(u, v)\n",
    "        # express r(u,v) as matrix additions\n",
    "        # YOUR CODE HERE\n",
    "        # u, v = \n",
    "        ###################\n",
    "        \n",
    "        h_states = [v, u]\n",
    "        ###################\n",
    "        # rollback backpointers\n",
    "        # y_{t-2} = bp[t, y_{t-1}, y_t]\n",
    "        # h_states is a reversed sequence of hidden states\n",
    "        # YOUR CODE HERE\n",
    "        # h_states = \n",
    "            \n",
    "        ###################\n",
    "        \n",
    "        return [self.hidden_idx2state[i] for i in reversed(h_states[:T])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a larger test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "tags:  NNP NNP , CD NNS JJ , MD VB DT NN IN DT JJ NN NNP CD .\n"
     ]
    }
   ],
   "source": [
    "data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:3300]\n",
    "\n",
    "X_train = [[x[0] for x in y] for y in data]\n",
    "y_train = [[x[1] for x in y] for y in data]\n",
    "\n",
    "X_test = [[x[0] for x in y] for y in test_data]\n",
    "y_test = [[x[1] for x in y] for y in test_data]\n",
    "\n",
    "print('sentence: ', \" \".join(X_train[0]))\n",
    "print('tags: ', \" \".join(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:46<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424766977363515\n",
      "CPU times: user 46.7 s, sys: 104 ms, total: 46.8 s\n",
      "Wall time: 46.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hh = HmmVectorized().fit(X_train, y_train)\n",
    "y_pred = hh.predict(X_test)\n",
    "print(accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accuracy must be > 0.84 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-2a546e209078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA_rowsum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "hh.A_rowsum[:, 5].reshape(hh.h_dim, hh.h_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Spelling correction\n",
    "\n",
    "Given data of true_char corrupted\\_char build spelling correction model using HMM.    \n",
    "There are 2 datatsets (spelling10.txt, spelling20.txt) with 10% and 20% corruption probability respectively.  \n",
    "Each dataset contains 30556 words. Use first 28000 for training and the rest for testing. Estimate accuracy on the test subset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_states(filename):\n",
    "    with open(filename,'r',encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    words = data.split('\\n_ _\\n')\n",
    "\n",
    "    o_data = []\n",
    "    h_data = []\n",
    "\n",
    "    for word in words:\n",
    "        letters = word.split('\\n')\n",
    "        h_data.append([x.split(' ')[0] for x in letters])\n",
    "        o_data.append([x.split(' ')[1] for x in letters])\n",
    "\n",
    "    o_train, h_train = o_data[:28000], h_data[:28000]\n",
    "    o_test, h_test = o_data[28000:], h_data[28000:]\n",
    "    \n",
    "    return o_train,h_train,o_test,h_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "o_train,h_train,o_test,h_test = get_states('spelling10.txt')\n",
    "hh10 = HmmVectorized().fit(o_train, h_train)\n",
    "h_pred = hh10.predict(o_test)\n",
    "print(accuracy(h_test, h_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get > 93% accuracy (+3%) on spelling10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "o_train,h_train,o_test,h_test = get_states('spelling20.txt')\n",
    "hh20 = HmmVectorized().fit(o_train, h_train)\n",
    "h_pred = hh20.predict(o_test)\n",
    "print(accuracy(h_test, h_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get > 89% accuracy (+9%) on spelling20 dataset"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
